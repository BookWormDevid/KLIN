from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from helpers.analyze_safetensors_file import SafetensorsFileActions


class MetricCheck:
    def __init__(self):
        self.STFA = SafetensorsFileActions()

    def detailed_model_analysis(self, model, model_name):
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏"""
        print(f"\nüèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {model_name}")
        print("=" * 50)

        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"–ú–æ–¥–µ–ª—å: {model.__class__.__name__}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {model.config.num_labels}")

        # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        total_params = 0
        trainable_params = 0
        layer_stats = []

        for name, param in model.named_parameters():
            param_count = param.numel()
            total_params += param_count
            if param.requires_grad:
                trainable_params += param_count

            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–ª–æ—è–º
            layer_name = name.split(".")[0] if "." in name else name
            layer_stats.append(
                {
                    "layer": layer_name,
                    "name": name,
                    "shape": tuple(param.shape),
                    "parameters": param_count,
                    "trainable": param.requires_grad,
                    "mean": param.data.mean().item(),
                    "std": param.data.std().item(),
                }
            )

        print(f"üìä –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
        print(f"üéØ –û–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {trainable_params:,}")
        print(f"üìà –ü—Ä–æ—Ü–µ–Ω—Ç –æ–±—É—á–∞–µ–º—ã—Ö: {(trainable_params / total_params) * 100:.2f}%")

        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º —Å–ª–æ–µ–≤
        layer_df = pd.DataFrame(layer_stats)
        layer_summary = (
            layer_df.groupby("layer")
            .agg({"parameters": "sum", "trainable": "mean"})
            .sort_values("parameters", ascending=False)
        )

        print("\nüìã –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–ª–æ—è–º:")
        for layer, row in layer_summary.head(10).iterrows():
            trainable_pct = row["trainable"] * 100
            print(
                f"  {layer:20} {row['parameters']:>12,} params ({trainable_pct:.1f}% trainable)"
            )

        return layer_df

    def create_basic_plots(self, model, model_name):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–æ–¥–µ–ª–∏"""
        print(f"\nüìä –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ò–ö–û–í –î–õ–Ø: {model_name}")

        try:
            # –ì—Ä–∞—Ñ–∏–∫ 1: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
            classifier_weights = model.classifier.weight.data.cpu().flatten().numpy()
            classifier_bias = model.classifier.bias.data.cpu().numpy()

            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

            # 1. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –≤–µ—Å–æ–≤
            ax1.hist(
                classifier_weights,
                bins=50,
                alpha=0.7,
                color="skyblue",
                edgecolor="black",
            )
            ax1.set_title(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n{model_name}")
            ax1.set_xlabel("–ó–Ω–∞—á–µ–Ω–∏–µ –≤–µ—Å–∞")
            ax1.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
            ax1.grid(True, alpha=0.3)

            # 2. –ó–Ω–∞—á–µ–Ω–∏—è —Å–º–µ—â–µ–Ω–∏–π
            classes = range(len(classifier_bias))
            bars = ax2.bar(classes, classifier_bias, color=["lightcoral", "lightgreen"])
            ax2.set_title("–°–º–µ—â–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º")
            ax2.set_xlabel("–ö–ª–∞—Å—Å")
            ax2.set_ylabel("–ó–Ω–∞—á–µ–Ω–∏–µ —Å–º–µ—â–µ–Ω–∏—è")
            ax2.set_xticks(classes)
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
            for bar, value in zip(bars, classifier_bias, strict=False):
                ax2.text(
                    bar.get_x() + bar.get_width() / 2,
                    bar.get_height(),
                    f"{value:.4f}",
                    ha="center",
                    va="bottom",
                )
            ax2.grid(True, alpha=0.3)

            # 3. Heatmap –≤–µ—Å–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            weights_2d = model.classifier.weight.data.cpu().numpy()
            im = ax3.imshow(weights_2d, aspect="auto", cmap="coolwarm")
            ax3.set_title("–ú–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞")
            ax3.set_xlabel("–ü—Ä–∏–∑–Ω–∞–∫–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)")
            ax3.set_ylabel("–ö–ª–∞—Å—Å—ã")
            ax3.set_xticks([])  # –£–±–∏—Ä–∞–µ–º –ø–æ–¥–ø–∏—Å–∏ –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è
            plt.colorbar(im, ax=ax3)

            # 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
            stats_data = {
                "–°—Ä–µ–¥–Ω–µ–µ": np.mean(classifier_weights),
                "–°—Ç–¥. –æ—Ç–∫–ª.": np.std(classifier_weights),
                "–ú–∏–Ω.": np.min(classifier_weights),
                "–ú–∞–∫—Å.": np.max(classifier_weights),
            }

            ax4.bar(stats_data.keys(), stats_data.values(), color="lightsteelblue")
            ax4.set_title("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Å–æ–≤")
            ax4.set_ylabel("–ó–Ω–∞—á–µ–Ω–∏–µ")
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
            for i, (_key, value) in enumerate(stats_data.items()):
                ax4.text(i, value, f"{value:.4f}", ha="center", va="bottom")
            ax4.grid(True, alpha=0.3)

            plt.tight_layout()
            plt.show()

            print("‚úÖ –ì—Ä–∞—Ñ–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω—ã!")

            # –í—ã–≤–æ–¥ —á–∏—Å–ª–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ú–û–î–ï–õ–ò {model_name}:")
            print("   –í–µ—Å–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞:")
            print(f"     - –°—Ä–µ–¥–Ω–µ–µ: {stats_data['–°—Ä–µ–¥–Ω–µ–µ']:.6f}")
            print(f"     - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {stats_data['–°—Ç–¥. –æ—Ç–∫–ª.']:.6f}")
            print(
                f"     - –î–∏–∞–ø–∞–∑–æ–Ω: [{stats_data['–ú–∏–Ω.']:.6f}, {stats_data['–ú–∞–∫—Å.']:.6f}]"
            )
            print(f"   –°–º–µ—â–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Å–∞–º: {classifier_bias}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")

    def run(self, path: Path):
        model_paths = self.STFA.find_safetensors_models(path)

        # –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–µ–π
        print("üîÑ –ü–ï–†–ï–ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê –° –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï–ú...")
        for _model_name, model_path in model_paths.items():
            self.STFA.analyze_safetensors_file_corrected(model_path)

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–µ–π
        models = {}
        for model_name, model_path in model_paths.items():
            print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_name}")
            model = self.STFA.load_model_from_safetensors(model_path)
            if model is not None:
                models[model_name] = model

        # –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        model_stats = {}
        for model_name, model in models.items():
            stats_df = self.detailed_model_analysis(model, model_name)
            model_stats[model_name] = stats_df
