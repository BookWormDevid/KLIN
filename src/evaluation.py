import os
import torch
import cv2
import numpy as np
from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor
from tqdm import tqdm
import pathlib

BASE_DIR = pathlib.Path(__file__).parent.parent


class VideoClassifier:
    def __init__(self, model_path: str = None, chunk_size: int = 16, frame_size: tuple = (224, 224)):
        self.chunk_size = chunk_size
        self.frame_size = frame_size
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        if model_path is None:
            model_path = self._find_model_path()

        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {model_path}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        self.processor = VideoMAEImageProcessor.from_pretrained(model_path, local_files_only=True)
        self.model = VideoMAEForVideoClassification.from_pretrained(model_path, local_files_only=True).to(self.device)
        self.model.eval()

        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª–∞—Å—Å—ã: {self.model.config.id2label}")

    def _find_model_path(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π—Ç–∏ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏"""
        possible_paths = [
            os.path.join(BASE_DIR, "models", "videomae-large")
        ]

        for path in possible_paths:
            if os.path.exists(path) and os.path.exists(os.path.join(path, "config.json")):
                return path

        print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
        model_path = input("üìÅ –í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—å—é: ")
        if os.path.exists(model_path):
            return model_path
        else:
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {model_path}")

    def _read_video_frames(self, video_path: str) -> np.ndarray:
        """–ß—Ç–µ–Ω–∏–µ –≤–∏–¥–µ–æ –∏ –≤–æ–∑–≤—Ä–∞—Ç –∫–∞–¥—Ä–æ–≤"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"Cannot open video: {video_path}")

        frames = []
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        duration = total_frames / fps if fps > 0 else 0

        print(f"üìπ –í–∏–¥–µ–æ: {os.path.basename(video_path)}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤: {total_frames}")
        print(f"   FPS: {fps:.2f}")
        print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.2f} —Å–µ–∫—É–Ω–¥")

        # –ß–∏—Ç–∞–µ–º –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä
        for _ in range(min(total_frames, 1000)):  # –æ–≥—Ä–∞–Ω–∏—á–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤
            ret, frame = cap.read()
            if not ret:
                break
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_resized = cv2.resize(frame_rgb, self.frame_size)
            frames.append(frame_resized)

        cap.release()

        if len(frames) == 0:
            raise ValueError(f"No frames read from video: {video_path}")

        return np.array(frames, dtype=np.uint8)

    def _chunk_frames(self, frames: np.ndarray) -> np.ndarray:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏"""
        t = len(frames)
        padding_needed = (-t) % self.chunk_size

        if padding_needed > 0:
            padding = np.zeros((padding_needed, *self.frame_size, 3), dtype=np.uint8)
            frames = np.concatenate([frames, padding], axis=0)

        num_chunks = len(frames) // self.chunk_size
        return frames.reshape(num_chunks, self.chunk_size, *self.frame_size, 3)

    def predict_video(self, video_path: str, batch_size: int = 4) -> dict:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ"""
        try:
            # –ß—Ç–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ
            frames = self._read_video_frames(video_path)
            chunks = self._chunk_frames(frames)

            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–¥—Ä–æ–≤: {len(frames)}")
            print(f"   –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")

            # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤
            all_predictions = []
            with torch.no_grad():
                for i in range(0, len(chunks), batch_size):
                    batch_chunks = chunks[i:i + batch_size]
                    batch_frames = [list(chunk) for chunk in batch_chunks]

                    inputs = self.processor(batch_frames, return_tensors="pt").to(self.device)
                    outputs = self.model(**inputs)
                    all_predictions.append(outputs.logits.cpu())

            # –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            final_logits = torch.mean(torch.cat(all_predictions), dim=0)
            probabilities = torch.nn.functional.softmax(final_logits, dim=0)
            predicted_idx = final_logits.argmax().item()
            confidence = probabilities[predicted_idx].item()

            # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∫–ª–∞—Å—Å–æ–≤
            class_probs = {}
            for idx, class_name in self.model.config.id2label.items():
                class_probs[class_name] = probabilities[idx].item()

            result = {
                'video_name': os.path.basename(video_path),
                'video_path': video_path,
                'predicted_class': self.model.config.id2label[predicted_idx],
                'confidence': confidence,
                'all_predictions': class_probs,
                'num_frames': len(frames),
                'num_chunks': len(chunks)
            }

            return result

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {os.path.basename(video_path)}: {e}")
            return {
                'video_name': os.path.basename(video_path),
                'video_path': video_path,
                'predicted_class': 'ERROR',
                'confidence': 0.0,
                'error': str(e)
            }


def process_video(input_path: str, model_path: str = None):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –∏–ª–∏ –ø–∞–ø–∫–∏ —Å –≤–∏–¥–µ–æ"""

    # –ï—Å–ª–∏ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    if model_path is None:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        possible_paths = [
            os.path.join(current_dir, "models", "KLIN-model"),
        ]

        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                break

    if model_path is None or not os.path.exists(model_path):
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏:")
        model_path = input("–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—å—é: ")

    print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: {model_path}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    classifier = VideoClassifier(model_path)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—É—Ç—å —Ñ–∞–π–ª–æ–º –∏–ª–∏ –ø–∞–ø–∫–æ–π
    if os.path.isfile(input_path):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        print("\n" + "=" * 50)
        print(f"üé¨ –û–ë–†–ê–ë–û–¢–ö–ê –í–ò–î–ï–û–§–ê–ô–õ–ê")
        print("=" * 50)

        result = classifier.predict_video(input_path)

        if result.get('error'):
            print(f"\n‚ùå –û—à–∏–±–∫–∞: {result['error']}")
            return

        print("\n" + "=" * 50)
        print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
        print("=" * 50)
        print(f"üìÅ –í–∏–¥–µ–æ: {result['video_name']}")
        print(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {result['predicted_class']}")
        print(f"üìà –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.4f} ({result['confidence'] * 100:.2f}%)")

        # –í—ã–≤–æ–¥ –≤—Å–µ—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        print("\nüìã –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤:")
        all_probs = result['all_predictions']
        sorted_probs = sorted(all_probs.items(), key=lambda x: x[1], reverse=True)

        for class_name, prob in sorted_probs:
            percentage = prob * 100
            if prob == result['confidence']:
                print(f"   ‚úÖ {class_name}: {prob:.4f} ({percentage:.2f}%)")
            else:
                print(f"   üìä {class_name}: {prob:.4f} ({percentage:.2f}%)")

    elif os.path.isdir(input_path):
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏
        print("\n" + "=" * 50)
        print(f"üìÅ –û–ë–†–ê–ë–û–¢–ö–ê –ü–ê–ü–ö–ò –° –í–ò–î–ï–û")
        print("=" * 50)
        print(f"–ü–∞–ø–∫–∞: {input_path}")

        # –ü–æ–∏—Å–∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤
        video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm')
        video_files = []

        for root, dirs, files in os.walk(input_path):
            for file in files:
                if file.lower().endswith(video_extensions):
                    video_files.append(os.path.join(root, file))

        print(f"–ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤: {len(video_files)}")

        if len(video_files) == 0:
            print("‚ùå –í–∏–¥–µ–æ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –≤–∏–¥–µ–æ
        results = []
        for video_path in tqdm(video_files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ"):
            result = classifier.predict_video(video_path)
            results.append(result)

            if not result.get('error'):
                print(
                    f"\nüìπ {os.path.basename(video_path)}: {result['predicted_class']} ({result['confidence'] * 100:.1f}%)")
            else:
                print(f"\n‚ùå {os.path.basename(video_path)}: –û—à–∏–±–∫–∞ - {result.get('error', 'Unknown')}")

        # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        successful = [r for r in results if not r.get('error')]
        errors = [r for r in results if r.get('error')]

        print("\n" + "=" * 50)
        print(f"üìà –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("=" * 50)
        print(f"–í—Å–µ–≥–æ –≤–∏–¥–µ–æ: {len(results)}")
        print(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(successful)}")
        print(f"–û—à–∏–±–æ–∫: {len(errors)}")

        if successful:
            avg_confidence = sum(r['confidence'] for r in successful) / len(successful)
            print(f"–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.4f} ({avg_confidence * 100:.2f}%)")

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º
            class_dist = {}
            for r in successful:
                cls = r['predicted_class']
                class_dist[cls] = class_dist.get(cls, 0) + 1

            print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
            for cls, count in sorted(class_dist.items()):
                percentage = (count / len(successful)) * 100
                print(f"   {cls}: {count} –≤–∏–¥–µ–æ ({percentage:.1f}%)")
    else:
        print(f"‚ùå –ü—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_path}")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –∫–∞–∫ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, —Ç–∞–∫ –∏ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ
    input_path = r"C:\Users\meksi\Documents\GitHub\KLIN\data\raw\KLIN\Test"

    # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
    model_path = r"C:\Users\meksi\Documents\GitHub\KLIN\models\KLIN-model"

    # –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    process_video(
        input_path=input_path,
        model_path=model_path
    )