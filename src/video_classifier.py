import os
import torch
import cv2
import numpy as np
from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor
from tqdm import tqdm
import pandas as pd
import pathlib
BASE_DIR = pathlib.Path(__file__).parent.parent

class VideoFolderClassifier:
    def __init__(self, model_path: str = None, chunk_size: int = 16, frame_size: tuple = (224, 224)):
        self.chunk_size = chunk_size
        self.frame_size = frame_size
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
        if model_path is None:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—â–µ–º –º–æ–¥–µ–ª—å –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏–ª–∏ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö
            model_path = self._find_model_path()

        print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑: {model_path}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        self.processor = VideoMAEImageProcessor.from_pretrained(model_path, local_files_only=True)
        self.model = VideoMAEForVideoClassification.from_pretrained(model_path, local_files_only=True).to(self.device)
        self.model.eval()

        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –ö–ª–∞—Å—Å—ã: {self.model.config.id2label}")

    def _find_model_path(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π—Ç–∏ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏"""
        possible_paths = [
            os.path.join(BASE_DIR, "models", "videomae-large")
        ]

        for path in possible_paths:
            if os.path.exists(path) and os.path.exists(os.path.join(path, "config.json")):
                return path

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –∑–∞–ø—Ä–æ—Å–∏–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
        model_path = input("üìÅ –í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—å—é: ")
        if os.path.exists(model_path):
            return model_path
        else:
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {model_path}")

    def _read_video_frames(self, video_path: str) -> np.ndarray:
        """Read video and return frames as numpy array"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"Cannot open video: {video_path}")

        frames = []
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # –ß–∏—Ç–∞–µ–º –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä
        for _ in range(min(total_frames, 1000)):  # –æ–≥—Ä–∞–Ω–∏—á–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤
            ret, frame = cap.read()
            if not ret:
                break
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_resized = cv2.resize(frame_rgb, self.frame_size)
            frames.append(frame_resized)

        cap.release()

        if len(frames) == 0:
            raise ValueError(f"No frames read from video: {video_path}")

        return np.array(frames, dtype=np.uint8)

    def _chunk_frames(self, frames: np.ndarray) -> np.ndarray:
        """Split frames into chunks with padding if needed"""
        t = len(frames)
        padding_needed = (-t) % self.chunk_size

        if padding_needed > 0:
            padding = np.zeros((padding_needed, *self.frame_size, 3), dtype=np.uint8)
            frames = np.concatenate([frames, padding], axis=0)

        num_chunks = len(frames) // self.chunk_size
        return frames.reshape(num_chunks, self.chunk_size, *self.frame_size, 3)

    def predict_video(self, video_path: str, batch_size: int = 4) -> dict:
        """Predict single video"""
        try:
            # Process video
            frames = self._read_video_frames(video_path)
            chunks = self._chunk_frames(frames)

            print(f"üìπ {os.path.basename(video_path)}: {len(frames)} frames -> {len(chunks)} chunks")

            # Batch process chunks
            all_predictions = []
            with torch.no_grad():
                for i in range(0, len(chunks), batch_size):
                    batch_chunks = chunks[i:i + batch_size]
                    batch_frames = [list(chunk) for chunk in batch_chunks]

                    inputs = self.processor(batch_frames, return_tensors="pt").to(self.device)
                    outputs = self.model(**inputs)
                    all_predictions.append(outputs.logits.cpu())

            # Aggregate results
            final_logits = torch.mean(torch.cat(all_predictions), dim=0)
            probabilities = torch.nn.functional.softmax(final_logits, dim=0)
            predicted_idx = final_logits.argmax().item()
            confidence = probabilities[predicted_idx].item()

            return {
                'video_name': os.path.basename(video_path),
                'video_path': video_path,
                'predicted_class': self.model.config.id2label[predicted_idx],
                'confidence': confidence,
                'num_frames': len(frames),
                'num_chunks': len(chunks)
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {os.path.basename(video_path)}: {e}")
            return {
                'video_name': os.path.basename(video_path),
                'video_path': video_path,
                'predicted_class': 'ERROR',
                'confidence': 0.0,
                'error': str(e)
            }

    def predict_folder(self, folder_path: str, output_file: str = None, batch_size: int = 4) -> pd.DataFrame:
        """Predict all videos in folder"""

        if not os.path.exists(folder_path):
            raise FileNotFoundError(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")

        # Find all video files
        video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm')
        video_files = []

        for root, dirs, files in os.walk(folder_path):
            for file in files:
                if file.lower().endswith(video_extensions):
                    video_files.append(os.path.join(root, file))

        print(f"üéØ –ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–æ–≤: {len(video_files)}")

        if len(video_files) == 0:
            print("‚ùå –í–∏–¥–µ–æ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return pd.DataFrame()

        # Process all videos
        results = []
        for video_path in tqdm(video_files, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ"):
            result = self.predict_video(video_path, batch_size)
            results.append(result)

        # Create DataFrame
        df = pd.DataFrame(results)

        # Save results if output file specified
        if output_file:
            df.to_csv(output_file, index=False, encoding='utf-8')
            print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")

        # Print summary
        self._print_summary(df)

        return df

    def _print_summary(self, df: pd.DataFrame):
        """Print processing summary"""
        if len(df) == 0:
            return

        successful = df[df['predicted_class'] != 'ERROR']
        errors = df[df['predicted_class'] == 'ERROR']

        print(f"\nüìä –°–í–û–î–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:")
        print(f"   –í—Å–µ–≥–æ –≤–∏–¥–µ–æ: {len(df)}")
        print(f"   –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(successful)}")
        print(f"   –û—à–∏–±–æ–∫: {len(errors)}")

        if len(successful) > 0:
            print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {successful['confidence'].mean():.4f}")

            # Class distribution
            class_counts = successful['predicted_class'].value_counts()
            print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
            for class_name, count in class_counts.items():
                percentage = (count / len(successful)) * 100
                print(f"     {class_name}: {count} –≤–∏–¥–µ–æ ({percentage:.1f}%)")

        if len(errors) > 0:
            print(f"\n‚ùå –û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            for _, error_row in errors.iterrows():
                print(f"   {error_row['video_name']}: {error_row.get('error', 'Unknown error')}")


# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
def process_video_folder_simple(folder_path, model_path=None, output_file="video_results.csv"):
    """–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–ø–∫–∏ —Å –≤–∏–¥–µ–æ"""

    # –ï—Å–ª–∏ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
    if model_path is None:
        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        current_dir = os.path.dirname(os.path.abspath(__file__))
        possible_paths = [
            os.path.join(current_dir, "videomae_results", "checkpoint-14172"),
            os.path.join(current_dir, "checkpoint-14172"),
            os.path.join(os.path.dirname(current_dir), "videomae-base-finetuned-klin",
                         "checkpoint-24536")
        ]

        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                break

    if model_path is None:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏:")
        model_path = input("–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –º–æ–¥–µ–ª—å—é: ")

    print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: {model_path}")
    print(f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º–∞—è –ø–∞–ø–∫–∞: {folder_path}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    classifier = VideoFolderClassifier(model_path)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏
    results = classifier.predict_folder(
        folder_path=folder_path,
        output_file=output_file
    )

    return results


# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫
if __name__ == "__main__":
    # –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –≤–∞—à–µ–π –ø–∞–ø–∫–µ —Å –≤–∏–¥–µ–æ
    video_folder = r"/home/cipher/Documents/VS_code/KLIN/data/raw/KLIN/Test/violent"

    # –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    model_path = "/home/cipher/Documents/VS_code/KLIN/videomae_results/checkpoint-28344" # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫

    results = process_video_folder_simple(
        folder_path=video_folder,
        model_path=model_path,
        output_file="video_classification_results.csv"
    )

    # –ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if not results.empty:
        print("\nüìã –ü–µ—Ä–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(results.head(10))